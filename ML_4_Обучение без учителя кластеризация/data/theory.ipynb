{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Введение</center>\n",
    "\n",
    "К обучению без учителя можно отнести:\n",
    "\n",
    "* **Методы кластеризации**. Они позволяют разделить объекты на группы, внутри которых объекты максимально похожи друг на друга.\n",
    "\n",
    "* **Методы понижения размерности**. С их помощью можно уменьшить число признаков, которые характеризуют объект. Обычно количество признаков уменьшают до двух-трёх для дальнейшей визуализации данных или использования при обучении моделей.\n",
    "\n",
    "* **Методы ассоциации**. Они используются для того, чтобы найти правила и законы, по которым существует последовательность действий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Базовая кластеризация</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация позволяет разбить объекты на группы, которые называются **кластерами**.\n",
    "\n",
    "**Центроид** — это центр масс кластера, или среднее значение координат объектов кластера. Для нахождения центроида мы берём все значения по оси *x* и считаем среднее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Алгоритм k-means</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Идея алгоритма** состоит в том, что он разбивает множество элементов векторного пространства на заранее заданное пользователем число кластеров, а далее стремится минимизировать суммарное квадратичное отклонение объектов внутри кластера до центроида кластера.\n",
    "\n",
    "Математически это выглядит следующим образом: \n",
    "\n",
    "$$V = \\sum_{i=1}^{k} \\sum_{x\\in S_{i}} (x - \\mu_{i})^2$$\n",
    "\n",
    "Мы итерируемся по каждому кластеру и для всех векторов $x$ внутри кластера $S_{i}$ подсчитываем центроиды ($\\mu_{i}$). Далее рассчитываем разницу между каждым вектором $x$ кластера $S_{i}$ и центроидом кластера $S_{i}$. Необходимо, чтобы это значение, возведённое в квадрат ($V$), было минимальным для каждого кластера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм *k-means* состоит из девяти шагов:\n",
    "\n",
    "1) Решаем, на сколько кластеров хотим разделить данные.\n",
    "\n",
    "2) Чтобы сформировать кластеры, случайным образом выбираем три объекта из датасета. Эти три объекта будут представлять три разных кластера (жёлтый, розовый и зелёный). Так как в этих кластерах находится по одному объекту, то эти объекты будут считаться исходными центроидами кластеров.\n",
    "\n",
    "3) Распределим оставшиеся объекты датасета по трём кластерам. (Считается, что объект принадлежит к тому кластеру, к центроиду которого он находится ближе всего.)\n",
    "\n",
    "4) Теперь в каждом из кластеров больше одного объекта, и центр этих кластеров тоже изменился. Поэтому рассчитаем новые центроиды.\n",
    "\n",
    "5) После этого для каждого объекта в выборке повторяем шаг 3, т. е. для каждого объекта датасета рассчитываем расстояние до центроидов. Так как у нас новые кластеры, центроиды могли сильно измениться. Поэтому при подсчёте расстояний ближайшим к объекту может оказаться уже другой центроид. Значит, этот объект будет принадлежать к другому кластеру.\n",
    "\n",
    "6) Шаг 5 повторяется до тех пор, пока объекты датасета не перестанут менять кластеры, к которым они относятся. Как только объекты перестают это делать, алгоритм завершается и мы переходим к шагу 7.\n",
    "\n",
    "7) Далее для каждого кластера подсчитаем средний квадрат расстояния от объектов до центров их кластеров. Находим суммарное отклонение.\n",
    "\n",
    "8) Далее мы несколько раз заново запускаем алгоритм кластеризации, начиная с шага 2. В шаге 1 мы выбирали первые объекты кластера случайным образом, но так можно выбрать не разные объекты, а те, что находятся рядом. В таком случае кластеризация получится некачественной. Чтобы такого не происходило, мы повторяем весь алгоритм несколько раз, начиная с шага 2. В *sklearn* по умолчанию проводится десять итераций.\n",
    "\n",
    "9) Среди получившихся кластеров нам необходимо найти наилучший вариант кластеризации. Лучшей будет признана кластеризация с минимальным значением среднеквадратичного отклонения, которое рассчитывали на шаге 7.\n",
    "\n",
    "Очевидно, что если все объекты будут в одном кластере, это будет худший сценарий с максимальным среднеквадратичным отклонением. \n",
    "\n",
    "А если каждый объект будет принадлежать собственному кластеру, отклонение будет нулевым, так как один объект будет являться и объектом кластера, и его центром масс, а значит расстояние между объектом кластера и центроидом кластера равно нулю. Такое разбиение будет считаться переобучением, так как мы слишком подстраиваемся под данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Название|Принцип работы|\n",
    "|--------|--------------|\n",
    "|K-MEANS|Находит центроиды кластера как среднее значение координат.|\n",
    "|K-MEANS++|В классическом алгоритме *k-means* центроиды выбираются случайно, но это может приводить к тому, что два объекта, которые находятся близко друг к другу, будут центроидами двух разных кластеров — это будет приводить к долгой работе алгоритма.Алгоритм *k-means++* чуть «хитрее» и выбирает центроиды кластеров не совсем случайно.|\n",
    "|K-MEDIANS|На этапе поиска центроидов кластера находит не среднее значение координат, а медиану.|\n",
    "|K-MEDOIDS|Работает так же, как *k-medians*, но медианой кластера будет не какая-то точка в кластере, а объект, который находится ближе всего к этим координатам медианы кластера.|\n",
    "|FUZZY C-MEANS|Данный алгоритм разрешает нечётко присваивать кластеры. Каждый объект может принадлежать к разным кластерам с разной вероятностью.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы запустить алгоритм кластеризации *k-means*, нам нужна библиотека `sklearn` и модуль `KMeans`.\n",
    "\n",
    "**Что необходимо для запуска:**\n",
    "\n",
    "* Обязательно задать количество кластеров, на которые необходимо разделить данные.\n",
    "\n",
    "* Данные, т. е. параметры объектов ($x_{i}$), которые мы будем передавать в виде матрицы наблюдений *X*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# импортируем нужный модуль k-means-кластеризации\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# инициализируем алгоритм, при желании задаём разные параметры для алгоритма\n",
    "k_means = KMeans(n_clusters=2, init='k-means++', n_init=10, random_state=42)\n",
    "X = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "# обучаем модель на данных, передав матрицу наблюдений X\n",
    "k_means.fit(X)\n",
    "# получаем результаты кластеризации (список меток, к какому кластеру относится каждый объект из X)\n",
    "labels = k_means.labels_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нужно определить, к какому из существующих кластеров будут отнесены новые данные из `df2`, то мы просто воспользуемся методом `predict`:\n",
    "\n",
    "```python\n",
    "X_new = df2[[\"x1\", \"x2\", \"x3\"]]\n",
    "k_means.predict(X_new)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы запустить алгоритм, необходимо задать **параметры кластеризации**:\n",
    "\n",
    "* `n_clusters` — количество кластеров. По умолчанию — 8.\n",
    "\n",
    "* `init` — способ инициализации центроидов. Есть две опции: `random` (выбирает центроиды случайным образом) и `k-means++` (более «хитрый» алгоритм, который позволяет модели быстрее сходиться). По умолчанию используется `k-means++`.\n",
    "\n",
    "* `n_init` — количество случайных инициализаций алгоритма `k-means`. В конце будут выбраны те результаты, которые имеют наилучшие значения критерия `k-means`. По умолчанию `n_init = 10`.\n",
    "\n",
    "* `max_iter` — максимальное количество итераций алгоритма `k-means` при одном запуске. По умолчанию — 300.\n",
    "\n",
    "* `random_state` — параметр, который определяет генерацию случайных чисел для инициализации центроида. Чтобы детерминировать случайность, нужно задать какое-нибудь число."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

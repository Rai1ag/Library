{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В машинном обучении есть два типа параметров:\n",
    "\n",
    "* **Внутренние (параметры модели)** - Подбираются во время обучения и определяют, как использовать входные данные для получения необходимого результата. Например, это веса (коэффициенты уравнения) в линейной/логистической регрессии.\n",
    "\n",
    "* **Внешние (параметры алгоритма)** - Их принято называть **гиперпараметрами**. Внешние параметры могут быть произвольно установлены перед началом обучения и контролируют внутреннюю работу обучающего алгоритма. Например, это параметр регуляризации в линейной/логистической регрессии. Гиперпараметры отвечают за сложность взаимосвязи между входными признаками и целевой переменной, поэтому сильно влияют на модель и качество прогнозирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый алгоритм *МО* имеет набор гиперпараметров, которые определяют, как именно он строит модель на обучающей выборке. Например, в модуле *ML-2* для повышения эффективности модели мы уже рассматривали подбор параметра регуляризации $\\alpha$ для алгоритма линейной регрессии *Ridge*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # для матричных вычислений\n",
    "import pandas as pd # для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt # для визуализации\n",
    "import seaborn as sns # для визуализации\n",
    "from sklearn import linear_model # линейные модели\n",
    "from sklearn import metrics # метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#Создаем список из 20 возможных значений от 0.001 до 10\n",
    "alpha_list = np.linspace(0.01, 10, 20)\n",
    "#Создаем пустые списки, в которые будем добавлять результаты \n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for alpha in alpha_list:\n",
    "    #Создаем объект класса линейная регрессия с L2-регуляризацией\n",
    "    ridge_lr_poly = linear_model.Ridge(alpha=alpha, max_iter=10000)\n",
    "    #Обучаем модель предсказывать логарифм целевого признака\n",
    "    ridge_lr_poly.fit(X_train_scaled_poly, y_train_log)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    #Если обучили на логарифме, то от результата необходимо взять обратную функцию - экспоненту\n",
    "    y_train_predict_poly = np.exp(ridge_lr_poly.predict(X_train_scaled_poly))\n",
    "    y_test_predict_poly = np.exp(ridge_lr_poly.predict(X_test_scaled_poly))\n",
    "    #Рассчитываем метрику для двух выборок и добавляем их в списки\n",
    "    train_scores.append(metrics.mean_absolute_error(y_train, y_train_predict_poly))\n",
    "    test_scores.append(metrics.mean_absolute_error(y_test, y_test_predict_poly))\n",
    " \n",
    "#Визуализируем изменение R^2 в зависимости от alpha\n",
    "fig, ax = plt.subplots(figsize=(12, 4)) #фигура + координатная плоскость\n",
    "ax.plot(alpha_list, train_scores, label='Train') #линейный график для тренировочной выборки\n",
    "ax.plot(alpha_list, test_scores, label='Test') #линейный график для тестовой выборки\n",
    "ax.set_xlabel('Alpha') #название оси абсцисс\n",
    "ax.set_ylabel('MAE') #название оси ординат\n",
    "ax.set_xticks(alpha_list) #метки по оси абцисс\n",
    "ax.xaxis.set_tick_params(rotation=45) #поворот меток на оси абсцисс\n",
    "ax.legend(); #отображение легенды\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат:\n",
    "\n",
    "![image.png](https://lms-cdn.skillfactory.ru/assets/courseware/v1/47a7e0d5d24abca72171988571c18d13/asset-v1:Skillfactory+DSMED+2023+type@asset+block/dst-3-ml-7-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшее значение метрики соответствует $\\alpha=0.01$ (кстати, можно попробовать перебрать значения $alpha < 0.01$).\n",
    "\n",
    "В данном случае мы просто воспользовались циклом `for` и перебрали некоторые заданные значения *alpha*, хотя, по всей видимости, не самые оптимальные. Поэтому подобранные эмпирическим путём значения гиперпараметров с большей вероятностью дадут низкую прогностическую эффективность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также рассмотренный метод визуализации зависимости метрики от гиперпараметра позволяет выбрать только один внешний параметр, в данном случае — *alpha*. А что делать, если у нас не один, а несколько? \n",
    "\n",
    "Например, вспомним основные внешние параметры `DecisionTreeClassifier`:\n",
    "\n",
    "* `criterion` — критерий информативности. Может быть равен `'gini'` — критерий Джини — и `'entropy'` — энтропия Шеннона.\n",
    "* `max_depth` — максимальная глубина дерева. По умолчанию `None`, глубина дерева не ограничена.\n",
    "* `max_features` — максимальное число признаков, по которым ищется лучшее разбиение в дереве. По умолчанию `None`, то есть обучение производится на всех признаках.\n",
    "* `min_samples_leaf` — минимальное число объектов в листе. По умолчанию — 1.\n",
    "\n",
    "Мы, конечно, можем сделать кучу вложенных циклов. Однако, поскольку поиск оптимальных значений гиперпараметров является общераспространенной задачей *МО*, библиотека *scikit-learn* и другие предлагают методы, позволяющие её решить.\n",
    "\n",
    "> Тщательный подбор гиперпараметров гарантирует, что модель покажет максимально возможную точность на обучающих данных, но это **совершенно не означает хороший результат на тестовых или новых данных**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Базовая оптимизация</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В базовой оптимизации, предоставляемой библиотекой *sklearn*, есть два основных метода — **grid search** и **random search**.\n",
    "\n",
    "Наиболее часто используемый метод — это **поиск по сетке (grid search)**, который по сути является попыткой перебрать все возможные комбинации заданных гиперпараметров. Мы указываем список значений для различных гиперпараметров, и, ориентируясь на нашу метрику, оцениваем эффективность модели для каждого их сочетания, чтобы получить оптимальную комбинацию значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы хотим подобрать гиперпараметры `min_samples_leaf` и `max_depth` для алгоритма `DecisionTreeClassifier`. Зададим списки их значений:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "min_samples_leaf = [3, 5, 8, 9]\n",
    "max_depth = [4, 5, 6, 7, 8]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку нам нужно перебрать четыре различных значения для `min_samples_leaf` и пять — для `max_depth`, то получается всего 4*5=20 комбинаций. Модель будет обучена 20 раз; столько же раз будет рассчитана метрика."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы перебираем множество значений гиперпараметров и выбираем ту комбинацию значений, которая даёт наилучшую точность на тестовых данных. Однако это **совсем не означает, что на новых данных мы получим такой же результат**. \n",
    "\n",
    "Поскольку мы использовали тестовый набор для настройки гиперпараметров, мы больше не можем использовать его для оценки качества модели. Теперь в этих целях нам необходим независимый набор данных, то есть набор, который не использовался для построения модели и настройки её гиперпараметров.\n",
    "\n",
    "Следовательно, надо разбить данные на **три части**: **обучающую** для построения модели, **проверочную** (валидационную) для выбора гиперпараметров модели, а также **тестовую** для оценки качества модели и выбранных гиперпараметров. \n",
    "\n",
    "Для лучшей оценки обобщающей способности вместо одного разбиения данных на обучающий и проверочный наборы мы можем воспользоваться перекрёстной проверкой, то есть **кросс-валидацией (cross validation)**. В таком случае качество модели оценивается для каждой комбинации гиперпараметров по всем разбиениям кросс-валидации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://lms-cdn.skillfactory.ru/assets/courseware/v1/761310cd7523c307072cadd085cf577e/asset-v1:Skillfactory+DSMED+2023+type@asset+block/dst-3-ml-7-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пояснение:**\n",
    "\n",
    "Предположим, что у нас есть *n* комбинаций гиперпараметров. Берём первую комбинацию и обучаем на них первую модель с помощью кросс-валидации с 10 фолдами (*cv=10*), затем рассчитываем метрику как среднее по всем разбиениям. Так проделываем для каждой комбинации и выбираем ту, при которой наша метрика наилучшая. В итоге мы обучим *n*cv* моделей, но выберем один набор гиперпараметров, который и будет использоваться для обучения итоговой модели на всей обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>GridSearchCV</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку поиск по сетке с кросс-валидацией является весьма распространённым методом настройки гиперпараметров, библиотека *scikit-learn* предлагает класс `GridSearchCV`, в котором осуществляется именно такой вариант."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*P.S. Смотри ноутбук \"extra: GridSearchCV\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основные параметры `GridSearchCV`:**\n",
    "\n",
    "* `estimator` — алгоритм, который будем оптимизировать;\n",
    "* `param_grid` — словарь или список словарей. Словарь с именами гиперпараметров (в формате строки (*str*), например, `'max_depth'`) в качестве ключей и списками параметров (например, `[5, 8, 10]`) в качестве значений. Итого: `{'max_depth': [5, 8, 10] }`.\n",
    "Также можно передать список таких словарей:\n",
    "```python\n",
    "param_grid = [\n",
    "              {'max_depth': [5, 8, 10],\n",
    "               'min_samples_leaf': [7, 8, 9] } #первый словарь \n",
    "               \n",
    "              {'n_estimators': [100, 200, 300], \n",
    "               'max_depth': [5, 8, 10] } #второй словарь \n",
    "             ]\n",
    "```\n",
    "В таком случае каждый словарь в списке перебирается отдельно и последовательно.\n",
    "\n",
    "* `scoring` — по умолчанию используется *score*-функция заданного алгоритма:\n",
    "    * для классификации — `sklearn.metrics.accuracy_score`;\n",
    "    * для регрессии — `sklearn.metrics.r2_score`;\n",
    "\n",
    "* `cv` — количество фолдов в кросс-валидации, по умолчанию используется 5.\n",
    "* `n_jobs` — количество ядер для распараллеливания расчёта. -1 использует все существующие ядра."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы воспользоваться классом `GridSearchCV`, необходимо:\n",
    "\n",
    "1) Импортировать библиотеку:\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "```\n",
    "\n",
    "2) Указать искомые гиперпараметры в виде словаря  `param_grid`: ключами словаря являются имена настраиваемых гиперпараметров, а значениями – тестируемые настройки гиперпараметров. Мы рассмотрим сетку из:\n",
    "    * `'penalty'` — тип регуляризации. Может принимать значения `l1`,  `l2`, `'elasticnet'` или `None` (отсутствие регуляризации);\n",
    "    * `'solver'` — алгоритм оптимизации, может принимать значения `'newton-cg'`, `'lbfgs'`, `'liblinear'`, `'sag'`, `'saga'`, по умолчанию — `'lbfgs'`.\n",
    "\n",
    "> Важно помнить, что выбор алгоритма оптимизации зависит от выбранного типа штрафа:\n",
    "\n",
    "![image.png](https://lms-cdn.skillfactory.ru/assets/courseware/v1/843b8646e16b0a034ea479809c4a8d5c/asset-v1:Skillfactory+DSMED+2023+type@asset+block/dst-3-ml-7-5.png)\n",
    "\n",
    "```python\n",
    "param_grid = {'penalty': ['l2', 'none'] ,#тип регурялизации\n",
    "                  'solver': ['lbfgs', 'saga'] #алгоритм оптимизации\n",
    "                  }\n",
    "```\n",
    "\n",
    "3) Вызвать класс `GridSearchCV` и передать модель (`LogisticRegression`), сетку искомых параметров (`param_grid`), а также число фолдов, которые мы хотим использовать в кросс-валидации, и `n_jobs = -1`, чтобы использовать все доступные ядра для расчётов:\n",
    "```python\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=1, #генератор случайных чисел\n",
    "        max_iter=1000 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")\n",
    "```\n",
    "\n",
    "4) Созданный нами объект `grid_search` аналогичен классификатору, поэтому мы можем вызвать стандартные методы `fit`, `predict` и `score` от его имени. Однако, когда мы вызываем `fit()`, он запускает кросс-валидацию для каждой комбинации гиперпараметров, указанных в `param_grid`:\n",
    "```python\n",
    "grid_search.fit(X_train_scaled, y_train) \n",
    "#Затраченное время: 1min 4s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `GridSearchCV` включает в себя не только поиск лучших параметров, но и автоматическое построение новой модели на всём обучающем наборе данных с использованием параметров, которые дают наилучшее значение метрики при кросс-валидации.\n",
    "\n",
    "Наилучшая найденная комбинация гиперпараметров сохраняется в атрибуте `best_params_`:\n",
    "```python\n",
    "print(\"Наилучшие значения параметров: {}\".format(grid_search.best_params_))\n",
    "# Наилучшие значения гиперпараметров: {'penalty': 'none', 'solver': 'lbfgs'}\n",
    "```\n",
    "\n",
    "Наилучшая метрика:\n",
    "```python\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search.score(X_test_scaled, y_test)))\n",
    "```\n",
    "\n",
    "Либо можем посмотреть любую другую метрику, воспользовавшись методом `predict()` и передав предсказанные значения в функцию для расчёта метрики (например, `f1_score()`):\n",
    "```python\n",
    "y_test_pred = grid_search.predict(X_test_scaled)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    " \n",
    "# accuracy на тестовом наборе: 0.84\n",
    "# f1_score на тестовом наборе: 0.64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрик не изменились, но это значит лишь, что мы не нашли комбинацию внешних параметров лучше, чем заданы по умолчанию. Это неудивительно, и достаточно часто исходные  гиперпараметры дают неплохой результат, но это не повод останавливаться!\n",
    "\n",
    "Попробуем расширить сетку гиперпараметров и проделаем те же шаги:\n",
    "\n",
    "```python\n",
    "param_grid = [\n",
    "              {'penalty': ['l2', 'none'] , # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регуляризации\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "]\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=1, max_iter=1000), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    " \n",
    "# %time - замеряет время выполнения\n",
    "%time grid_search_1.fit(X_train_scaled, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_1.score(X_test_scaled, y_test)))\n",
    "y_test_pred = grid_search_1.predict(X_test_scaled)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_1.best_params_))\n",
    " \n",
    "#Затраченное время: 5min 43s (индивидуально, для каждого ПК)\n",
    "#accuracy на тестовом наборе: 0.84\n",
    "#f1_score на тестовом наборе: 0.64\n",
    "#Наилучшие значения гиперпараметров: {'C': 0.3, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "```\n",
    "\n",
    "Метрику опять не удалось улучшить, а времени потратили много, в пять раз больше!\n",
    "\n",
    "Поиск по сетке не гарантирует, что мы найдём наилучшую комбинацию гиперпараметров. Всё потому, что сетка значений конечна, и фактическое наилучшее значение может отсутствовать или оказаться между значений, заданными нами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая модель хранится в параметре `best_estimator_`, ей можно воспользоваться для получения прогнозов на новых данных: \n",
    "```python\n",
    "print(\"Наилучшая модель:\\n{}\".format(grid_search.best_estimator_))\n",
    "#Наилучшая модель: LogisticRegression(max_iter=1000, penalty='none', random_state=1)\n",
    "```\n",
    "\n",
    "А наилучшее значение метрики на кросс-валидации (значение метрики, усреднённое по всем разбиениям для данной комбинации гиперпараметров) хранится в атрибуте `best_score_`. \n",
    "```python\n",
    "print(\"Наилучшее значение точности при кросс-валидации: {:.2f}\".format(grid_search.best_score_))\n",
    "#Наилучшее значение точности при кросс-валидации: 0.84\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не путайте `best_score_` со значением метрики модели, которое вычисляется на тестовом наборе с помощью метода `score`. Метод `score` (оценивающий качество результатов, полученных с помощью метода `predict()`) использует модель, построенную на всём обучающем наборе данных. В атрибуте `best_score_` записывается средняя метрика на кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты кросс-валидации хранятся в параметре `cv_results_`. Отрисуем, как менялась метрика при различных гиперпараметрах:\n",
    "```python\n",
    "visual = pd.pivot_table(pd.DataFrame(grid_search_1.cv_results_),\n",
    "               values='mean_test_score', index='param_C',\n",
    "               columns='param_solver')\n",
    "sns.heatmap(visual)\n",
    "plt.title('Тепловая карта зависимости метрики accuracy от solver и С') # подпись графика\n",
    "sns.set(rc={'figure.figsize':(12, 8)}) #задаем размер графика\n",
    "```\n",
    "\n",
    "![image.png](https://lms-cdn.skillfactory.ru/assets/courseware/v1/d2640828dc452cc42cf52eff9678b850/asset-v1:Skillfactory+DSMED+2023+type@asset+block/dst-3-ml-7-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что слабая регуляризация *С = 0.01* отрицательно влияет на метрику, поэтому есть смысл брать значения больше 0.5 и алгоритмы оптимизации *lbfgs* и *sag* работают лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>RandomizedSearchCV</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативным подходом подбора различных комбинаций гиперпараметров в библиотеке *scikit-learn* является `RandomizedSearchCV`. \n",
    "\n",
    "Рандомизированный поиск работает почти так же, как решётчатый поиск, за исключением того, что перебираются не всевозможные комбинации параметров, а из них случайным образом выбираются $n$ возможных вариантов комбинаций. Количество комбинаций параметров ($n$), которые используются в случайном поиске, мы задаём самостоятельно, что позволяет управлять временем, затрачиваемым на оптимизацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://lms-cdn.skillfactory.ru/assets/courseware/v1/7bc80431d813a9af9a6ec0409c53c4df/asset-v1:Skillfactory+DSMED+2023+type@asset+block/dst-3-ml-7-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В `GridSearchCV` сетка задаётся вручную, перебираются различные значения гиперпараметров с каким-то шагом, в итоге получается что-то похожее на «красивую» сетку слева на картинке. Однако минимум функции (белое пятно) мы так и не обнаруживаем — а ведь он где-то рядом, возможно, просто между подобранными нами комбинациями.\n",
    "\n",
    "* `RandomizedSearchCV` выбирает *n* (количество задаём сами) случайных точек/комбинаций из заданных нами последовательностей. Как следствие, мы можем перебирать не все возможные точки, а только часть из них, тем самым управляя скоростью работы перебора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основные параметры `RandomizedSearchCV`** аналогичны `GridSearchCV`, за исключением наименований некоторых параметров и наличия параметра `n_iter`:\n",
    "\n",
    "* `estimator` — алгоритм, который будем оптимизировать;\n",
    "* `param_distributions` — cловарь с именами параметров (*str*) в качестве ключей и списками параметров в качестве значений, которые нужно попробовать.\n",
    "\n",
    "> В ранних версиях *sklearn* данный параметр был обозначен как `param_grid` (как и в `GridSearchCV`).\n",
    "\n",
    "Также можно передать список таких словарей:\n",
    "```python\n",
    "param_grid = [\n",
    "              {'max_depth': [5, 8, 10],\n",
    "               'min_samples_leaf': [7, 8, 9] } #первый словарь \n",
    "              {'n_estimators': [100, 200, 300], \n",
    "               'max_depth': [5, 8, 10] } #второй словарь \n",
    "             ]\n",
    "```\n",
    "В таком случае каждый словарь в списке перебирается отдельно и последовательно. Это позволяет выполнять поиск по любой последовательности настроек параметров.\n",
    "\n",
    "* `scoring` — по умолчанию используется score-функция заданного алгоритма:\n",
    "    * для классификации — `sklearn.metrics.accuracy_score`;\n",
    "    * для регрессии — `sklearn.metrics.r2_score`.\n",
    "\n",
    "* `cv` — количество фолдов в кросс-валидации, по умолчанию используется 5.\n",
    "* `n_jobs` — количество ядер для распараллеливания расчёта. -1 использует все существующие ядра.\n",
    "* `n_iter` — количество комбинаций на расчёт. От этого параметра напрямую зависит время оптимизации и качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*P.S. Смотри ноутбук \"extra: RandomizedSearchCV\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Рекомендации по настройке гиперпараметров ансамблей над решающими деревьями</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритм случайного леса (RandomForest)**\n",
    "\n",
    "* `n_estimators` — число итераций (количество деревьев). Частично работает правило «чем больше, тем лучше», но иногда это не имеет особого смысла и сильно увеличивает затраты, поэтому стоит пробовать обучать сотни деревьев [100,200, 300, 400]. Если нет изменений, то оставить минимальное — 100.\n",
    "\n",
    "* `max_depth` — максимальная глубина дерева. В случайном лесе строятся «сильные» деревья, каждое из которых даёт полноценный прогноз, поэтому глубина деревьем может быть достаточно большой. Стоит следить за переобучением.\n",
    "\n",
    "* `max_features` — максимальное количество признаков, учитываемых алгоритмом при поиске лучшего разделения;\n",
    "\n",
    "* `max_samples` — доля выборки, которая будет использоваться для обучения каждого алгоритма — дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритм градиентного бустинга (GradientBoosting)**\n",
    "\n",
    "* `n_estimators` — число итераций (количество деревьев) : хотя ошибка на обучении монотонно стремится к нулю, ошибка на контроле, как правило, начинает увеличиваться после определенной итерации. Оптимальное число итераций можно выбирать, например, по отложенной выборке или с помощью кросс-валидации.\n",
    "\n",
    "* `learning_rate` — темп обучения (0;1]. Как правило, чем меньше темп обучения, тем лучше качество итоговой композиции.\n",
    "\n",
    "* `max_depth` — максимальная глубина дерева. Используется для борьбы с переобучением. Рекомендуется устанавливать не более 5.\n",
    "\n",
    "* `max_features` — максимальное количество признаков, учитываемых алгоритмом при поиске лучшего разделения.\n",
    "\n",
    "* `subsample` — доля выборки, которая будет использоваться для обучения каждого алгоритма. Это ещё один способ улучшения качества градиентного бустинга. Таким образом вносится рандомизация в процесс обучения базовых алгоритмов, что снижает уровень шума в обучении, а также повышает эффективность вычислений. \n",
    "\n",
    "> **Рекомендация**. Берите подвыборки, размер которых вдвое меньше исходной выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Главное отличие техник *Bagging* и *Boosting* состоит в параллельном и последовательном построении деревьев соответственно.\n",
    "\n",
    "![image.png](https://lms-cdn.skillfactory.ru/assets/courseware/v1/45f50e8761202094e73aa7c1fa399014/asset-v1:Skillfactory+DSMED+2023+type@asset+block/dst-3-ml-7-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Общепринятая практика для бустинга — подгонять `n_estimators` в зависимости от бюджета времени и памяти, а затем подбирать различные значения `learning_rate`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Продвинутая оптимизация</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
